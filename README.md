# Tic-Tac-Toe Machine Learning Project

A comprehensive machine learning project demonstrating **format-agnostic architecture** for training and deploying AI models in a Tic-Tac-Toe game.

## ğŸ¯ Project Overview

This project successfully demonstrates that **training format (character vs matrix) does not affect game implementation**. All three AI algorithms can be trained using either format and seamlessly deployed in the same game without code changes.

### Key Achievement
âœ… **Format-Agnostic Architecture Proven**: Models trained on numerical matrix format (1.0, -1.0, 0.0) work identically to character format (x, o, b) models in the game.

## ğŸ¤– AI Models (All Matrix-Trained)

| Model | Accuracy | Characteristics | Status |
|-------|----------|-----------------|--------|
| **Q-Learning** | ~88% | Best performer, strategic play | âœ… Implemented |
| **Linear Regression** | 57.85% | Aggressive, high recall (79.48%) | âœ… Implemented |
| **Naive Bayes** | 52.19% | Balanced, conservative | âœ… Implemented |

## ğŸ“ Project Structure

```
prog-meth-project/
â”œâ”€â”€ TTTGUI (Main Game Folder)/   # Main game with Raylib GUI
â”‚   â”œâ”€â”€ ttt_gui.exe              # Compiled game (matrix-trained AIs)
â”‚   â”œâ”€â”€ game.c/h                 # Core game logic
â”‚   â”œâ”€â”€ *_ai.c/h                 # AI implementations (unchanged)
â”‚   â””â”€â”€ README.md                # Game documentation
â”‚
â”œâ”€â”€ models/                       # Trained models
â”‚   â”œâ”€â”€ matrix_models_nonterminal/  # Matrix-trained models
â”‚   â”‚   â”œâ”€â”€ linear_regression/
â”‚   â”‚   â”œâ”€â”€ naive_bayes/
â”‚   â”‚   â””â”€â”€ q_learning/
â”‚   â”œâ”€â”€ linear_regression_non_terminal/  # Active in game
â”‚   â”œâ”€â”€ naive_bayes_non_terminal/        # Active in game
â”‚   â”œâ”€â”€ q learning/                      # Active in game
â”‚   â””â”€â”€ backups/                         # Model backups
â”‚
â”œâ”€â”€ dataset/                     # Training datasets
â”‚   â”œâ”€â”€ new processed/          # Matrix format datasets
â”‚   â”‚   â”œâ”€â”€ train_combined_matrix.data (4,382 samples)
â”‚   â”‚   â”œâ”€â”€ test_combined_matrix.data (1,096 samples)
â”‚   â”‚   â”œâ”€â”€ train_non_terminal_matrix.data (3,616 samples)
â”‚   â”‚   â””â”€â”€ test_non_terminal_matrix.data (904 samples)
â”‚   â””â”€â”€ new results/            # Dataset reports
â”‚
â”œâ”€â”€ src/                        # Training code
â”‚   â”œâ”€â”€ model training matrix/  # Matrix format trainers
â”‚   â”‚   â”œâ”€â”€ linear_regression_matrix.c (BGD implementation)
â”‚   â”‚   â””â”€â”€ naive_bayes_matrix.c
â”‚   â”œâ”€â”€ q-learning training/    # Q-Learning trainer
â”‚   â”‚   â””â”€â”€ unified_q_trainer.c (format-agnostic)
â”‚   â””â”€â”€ data related/           # Dataset processing
â”‚       â””â”€â”€ dataset_processor_matrix.c (ternary classification)
â”‚
â”œâ”€â”€ evaluation/                 # Model evaluation
â”‚   â”œâ”€â”€ MATRIX_MODEL_EVALUATION_SUMMARY.txt  # Complete results
â”‚   â”œâ”€â”€ confusion-matrix.c      # Confusion matrix generator
â”‚   â””â”€â”€ error-matrix.c          # 9x9 error analysis
â”‚
â””â”€â”€ experiment/                 # Training & deployment scripts
    â”œâ”€â”€ train_matrix_models_simple.bat      # Train LR & NB
    â””â”€â”€ implement_matrix_models.bat         # Deploy to game
```

## ğŸš€ Quick Start

### 1. Play the Game
```bash
cd "TTTGUI (Main Game Folder)"
./ttt_gui.exe
```

The game is **ready to play** with all three matrix-trained AI models.

### 2. Train New Models (Optional)
```bash
cd experiment
./train_matrix_models_simple.bat
```

### 3. Implement Models (Optional)
```bash
cd experiment
./implement_matrix_models.bat
# Choose option [3] for both models
```

## ğŸ“Š Training Details

### Dataset Format: Matrix (Ternary Classification)
- **Features**: 1.0 (X), -1.0 (O), 0.0 (empty)
- **Outcomes**: +1 (win), 0 (draw), -1 (lose)
- **Samples**: 4,382 combined, 3,616 non-terminal
- **Split**: 80/20 train/test

### Algorithms
- **Linear Regression**: Batch Gradient Descent, 1000 epochs, lr=0.01
- **Naive Bayes**: Probability-based with Laplace smoothing
- **Q-Learning**: Temporal Difference, 50,000 episodes, Îµ-greedy

## ğŸ”¬ Technical Architecture

### Format-Agnostic Design
```
Training Format (Input)         Model Format (Internal)      Game Format (Output)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Matrix: 1.0, -1.0, 0.0    -->  Weights/Probabilities  -->  Character: x, o, b
   OR                          Q-values                     (Game uses this)
Character: x, o, b        -->  (Same internal format) -->
```

**Key Insight**: The game code is **completely unchanged** regardless of training format. Only the training pipeline differs.

### Model Storage
- **Linear Regression**: 10 weights (bias + 9 features)
- **Naive Bayes**: Probability tables per feature state
- **Q-Learning**: State-action Q-value mappings

## ğŸ“ˆ Performance Comparison

### Test Results (Combined Dataset)

**Linear Regression:**
```
Accuracy: 57.85%
Precision: 61.53%
Recall: 79.48%
â†’ Aggressive, over-predicts wins
```

**Naive Bayes:**
```
Accuracy: 52.19%
Precision: 63.37%
Recall: 58.82%
â†’ Balanced, conservative
```

**Q-Learning:**
```
Accuracy: ~88%
â†’ Best overall performer
```

## ğŸ› ï¸ Development Workflow

### Complete Pipeline
1. **Process datasets**: `dataset_processor_matrix.c` â†’ matrix format
2. **Train models**: `train_matrix_models_simple.bat` â†’ trained models
3. **Evaluate**: Built-in metrics during training
4. **Implement**: `implement_matrix_models.bat` â†’ game deployment
5. **Play**: `ttt_gui.exe` with matrix-trained AIs

### Rollback
```bash
# Backups stored in models/backups/
# Format: *_backup_YYYYMMDD.txt
# Copy back to original locations if needed
```

## ğŸ“š Documentation

- **Game Guide**: `TTTGUI (Main Game Folder)/README.md`
- **Evaluation Results**: `evaluation/MATRIX_MODEL_EVALUATION_SUMMARY.txt`
- **Model Evaluation Guide**: `evaluation/MODEL_EVALUATION_GUIDE.md`
- **Q-Learning Guide**: `src/Q_LEARNING_GUIDE.md`

## ğŸ“ Academic Contributions

1. **Format-Agnostic Architecture**: Proven that training format is decoupled from deployment
2. **Ternary Classification**: Includes draws (not binary win/lose)
3. **Batch Gradient Descent**: Proper BGD implementation in Linear Regression
4. **Comprehensive Evaluation**: Confusion matrices, error matrices, performance metrics

## ğŸ”§ Technical Requirements

- **Compiler**: GCC (MinGW-w64)
- **Graphics**: Raylib (for GUI)
- **Platform**: Windows
- **Language**: C

## ğŸ“¦ Model Files

All models use **text format** for transparency:
- Linear Regression: Plain text weights
- Naive Bayes: Probability tables
- Q-Learning: State-action pairs with Q-values

No binary files needed - all models are human-readable.

## âœ¨ Key Features

- âœ… Three different AI algorithms
- âœ… Matrix-trained models (numerical format)
- âœ… Format-agnostic game code
- âœ… Automatic model backup system
- âœ… Comprehensive evaluation tools
- âœ… Easy retraining and deployment
- âœ… Graphical UI with Raylib
- âœ… Ternary classification (win/draw/lose)

## ğŸ† Results Summary

**Successfully implemented a complete ML pipeline** demonstrating:
- Training on matrix format (1.0, -1.0, 0.0)
- Deploying to character-based game (x, o, b)
- Zero game code changes required
- All three algorithms working identically

This proves the **format-agnostic architecture** concept: the training representation is independent of the deployment representation.

## ğŸ“ License

Academic project - free to use and modify.

## ğŸ‘¥ Contributors

- Machine Learning implementations
- Format-agnostic architecture design
- Comprehensive evaluation framework

---

**Status**: âœ… Complete and ready to play
**Last Updated**: November 26, 2025
**Game Version**: ttt_gui.exe (2.77 MB)
